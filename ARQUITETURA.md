# ğŸ—ï¸ Arquitetura do Chatbot F1 - DocumentaÃ§Ã£o TÃ©cnica

## VisÃ£o Geral da Arquitetura

Este documento detalha a arquitetura completa do chatbot F1, incluindo diagramas visuais, decisÃµes tÃ©cnicas e fluxo de dados.

---

## ğŸ“Š Diagrama Visual da Arquitetura

![Arquitetura do Chatbot F1](/public/arquitetura-chatbot.png)

---

## ğŸ¯ PadrÃµes de Arquitetura Utilizados

### 1. RAG (Retrieval-Augmented Generation)

**O que Ã©?**

- PadrÃ£o arquitetural que combina busca de informaÃ§Ãµes (retrieval) com geraÃ§Ã£o de texto (generation)
- Permite que LLMs respondam com base em conhecimento externo atualizado

**Componentes:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           RAG Architecture Pattern               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  1. INDEXING (Offline)                          â”‚
â”‚     Documents â†’ Chunks â†’ Embeddings â†’ Vector DB â”‚
â”‚                                                  â”‚
â”‚  2. RETRIEVAL (Online)                          â”‚
â”‚     Query â†’ Embedding â†’ Vector Search â†’ Top-K   â”‚
â”‚                                                  â”‚
â”‚  3. GENERATION (Online)                         â”‚
â”‚     Context + Query â†’ LLM â†’ Response            â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Vantagens:**

- âœ… Respostas baseadas em fatos (nÃ£o alucinaÃ§Ãµes)
- âœ… Conhecimento atualizÃ¡vel sem retreinar modelo
- âœ… Rastreabilidade (podemos saber de onde veio a info)
- âœ… Custo menor que fine-tuning

**Desvantagens:**

- âš ï¸ LatÃªncia adicional (2 chamadas Ã  API)
- âš ï¸ Complexidade de infraestrutura (banco vetorial)
- âš ï¸ DependÃªncia da qualidade dos chunks

### 2. Server-Side Rendering + Client Components (Next.js)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Next.js Hybrid Architecture             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  SERVER COMPONENTS (page.tsx, layout.tsx)       â”‚
â”‚    - Renderizam no servidor                     â”‚
â”‚    - Zero JavaScript enviado ao cliente         â”‚
â”‚    - Acesso direto a banco de dados             â”‚
â”‚                                                  â”‚
â”‚  CLIENT COMPONENTS ("use client")               â”‚
â”‚    - Chat.tsx, LoadingBubble.tsx                â”‚
â”‚    - Interatividade (useState, onClick)         â”‚
â”‚    - JavaScript enviado ao navegador            â”‚
â”‚                                                  â”‚
â”‚  API ROUTES (/api/chat/route.ts)                â”‚
â”‚    - Backend integrado ao frontend              â”‚
â”‚    - Serverless functions                       â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. ETL Pipeline (Extract, Transform, Load)

```mermaid
flowchart TB
    subgraph EXTRACT
        A[Web Pages] --> B[Puppeteer]
        B --> C[HTML Content]
    end

    subgraph TRANSFORM
        C --> D[Strip HTML Tags]
        D --> E[Clean Text]
        E --> F[Text Splitter]
        F --> G[Chunks 512 chars]
        G --> H[Embedding Generator]
        H --> I[Vectors 768D]
    end

    subgraph LOAD
        I --> J[Batch Insert]
        J --> K[(Astra DB)]
    end

    style EXTRACT fill:#fff3cd
    style TRANSFORM fill:#d4edda
    style LOAD fill:#cfe2ff
```

---

## ğŸ”„ Fluxo de Dados Detalhado

### Fluxo 1: IndexaÃ§Ã£o (Executado uma vez)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ loadDb.ts    â”‚ Script executado com npm run seed
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â–º 1. Puppeteer navega para URL
       â”‚      - Carrega pÃ¡gina completa
       â”‚      - Aguarda JavaScript executar
       â”‚      - Extrai HTML do body
       â”‚
       â”œâ”€â–º 2. Limpeza de conteÃºdo
       â”‚      - Remove tags HTML (<p>, <div>, etc)
       â”‚      - Remove caracteres especiais
       â”‚      - MantÃ©m apenas texto puro
       â”‚
       â”œâ”€â–º 3. DivisÃ£o em chunks
       â”‚      - RecursiveCharacterTextSplitter
       â”‚      - Tamanho: 512 caracteres
       â”‚      - SobreposiÃ§Ã£o: 200 caracteres
       â”‚      - Preserva parÃ¡grafos quando possÃ­vel
       â”‚
       â”œâ”€â–º 4. GeraÃ§Ã£o de embeddings
       â”‚      - Para cada chunk:
       â”‚        â€¢ Chama Gemini text-embedding-004
       â”‚        â€¢ Recebe vetor de 768 nÃºmeros
       â”‚        â€¢ Vetor representa significado semÃ¢ntico
       â”‚
       â””â”€â–º 5. Armazenamento
            - Insere no Astra DB:
              â€¢ Campo $vector: [0.123, -0.456, ...]
              â€¢ Campo text: "conteÃºdo do chunk"
              â€¢ Indexed para busca vetorial
```

### Fluxo 2: Consulta em Tempo Real

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UsuÃ¡rio      â”‚ "Quem venceu o campeonato 2024?"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â–º FRONTEND (Chat.tsx)
       â”‚   â””â”€â–º handleSubmit()
       â”‚       - Adiciona mensagem ao estado
       â”‚       - Mostra loading bubble
       â”‚       - POST /api/chat
       â”‚
       â”œâ”€â–º BACKEND (route.ts)
       â”‚   â”‚
       â”‚   â”œâ”€â–º Etapa 1: ExtraÃ§Ã£o da pergunta
       â”‚   â”‚   - Pega Ãºltima mensagem do array
       â”‚   â”‚   - latestMessage = "Quem venceu..."
       â”‚   â”‚
       â”‚   â”œâ”€â–º Etapa 2: Embedding da pergunta
       â”‚   â”‚   - Gemini embedContent(latestMessage)
       â”‚   â”‚   - Retorna: vector[768] = [0.234, -0.567, ...]
       â”‚   â”‚
       â”‚   â”œâ”€â–º Etapa 3: Busca vetorial
       â”‚   â”‚   - collection.find({}, { sort: { $vector: vector }, limit: 10 })
       â”‚   â”‚   - Astra DB calcula similaridade (dot product)
       â”‚   â”‚   - Retorna 10 chunks mais similares
       â”‚   â”‚   - Exemplo:
       â”‚   â”‚       Chunk 1: "Max Verstappen venceu..."
       â”‚   â”‚       Chunk 2: "Red Bull Racing..."
       â”‚   â”‚       ...
       â”‚   â”‚
       â”‚   â”œâ”€â–º Etapa 4: ConstruÃ§Ã£o do prompt
       â”‚   â”‚   - SYSTEM: "VocÃª Ã© assistente F1..."
       â”‚   â”‚   - CONTEXT: JSON com os 10 chunks
       â”‚   â”‚   - USER: "Quem venceu..."
       â”‚   â”‚
       â”‚   â”œâ”€â–º Etapa 5: GeraÃ§Ã£o da resposta
       â”‚   â”‚   - generateText(model: gemini-2.5-flash)
       â”‚   â”‚   - LLM analisa context + pergunta
       â”‚   â”‚   - Gera resposta natural
       â”‚   â”‚
       â”‚   â””â”€â–º Etapa 6: Retorno
       â”‚       - JSON: { content: "Max Verstappen venceu..." }
       â”‚
       â””â”€â–º FRONTEND (Chat.tsx)
           - Recebe resposta
           - Adiciona ao estado messages[]
           - Remove loading bubble
           - Renderiza resposta na tela
```

---

## ğŸ§© Componentes da Arquitetura

### 1. Camada de ApresentaÃ§Ã£o (Frontend)

```typescript
// Estrutura de componentes React
app/
â”œâ”€â”€ page.tsx                    // Server Component (SEO, estÃ¡tico)
â”‚   â””â”€â”€ <Chat />                // Client Component (interativo)
       â”‚
       â”œâ”€â”€ <PromptSuggestionsRow />   // SugestÃµes de perguntas
       â”‚   â””â”€â”€ onClick â†’ handlePromptClick()
       â”‚
       â”œâ”€â”€ <LoadingBubble />          // AnimaÃ§Ã£o de loading
       â”‚   â””â”€â”€ CSS animations (3 bolinhas)
       â”‚
       â””â”€â”€ <form>                     // FormulÃ¡rio de envio
           â””â”€â”€ onSubmit â†’ handleSubmit()
```

**Responsabilidades:**

- âœ… Gerenciar estado de mensagens (`useState`)
- âœ… Capturar input do usuÃ¡rio
- âœ… Fazer chamadas HTTP para `/api/chat`
- âœ… Renderizar histÃ³rico de conversas
- âœ… Exibir loading states

### 2. Camada de API (Backend)

```typescript
// API Route Handler
app / api / chat / route.ts;

export async function POST(req: Request) {
  // 1. Parse do request
  const { messages } = await req.json();

  // 2. GeraÃ§Ã£o de embedding
  const embedding = await embedContent(latestMessage);

  // 3. Busca vetorial
  const docs = await collection.find({
    sort: { $vector: embedding },
  });

  // 4. GeraÃ§Ã£o de resposta
  const result = await generateText({
    model: gemini,
    system: template + context,
    messages,
  });

  // 5. Retorno
  return Response.json({ content: result.text });
}
```

**Responsabilidades:**

- âœ… Validar requests
- âœ… Orquestrar chamadas Ã  IA e banco de dados
- âœ… Tratamento de erros
- âœ… FormataÃ§Ã£o de respostas

### 3. Camada de Dados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Astra DB (Cassandra)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  Collection: f1_embeddings              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Document Structure:            â”‚    â”‚
â”‚  â”‚ {                              â”‚    â”‚
â”‚  â”‚   _id: "uuid-auto-generated",  â”‚    â”‚
â”‚  â”‚   $vector: [0.12, -0.34, ...], â”‚    â”‚
â”‚  â”‚   text: "chunk content..."     â”‚    â”‚
â”‚  â”‚ }                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚  Ãndice Vetorial:                      â”‚
â”‚  - Algoritmo: ANN (Approximate NN)     â”‚
â”‚  - MÃ©trica: dot_product                â”‚
â”‚  - DimensÃµes: 768                      â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Por que Astra DB?**

- âœ… **Vetorial nativo**: Suporta busca por similaridade out-of-the-box
- âœ… **Serverless**: NÃ£o precisa gerenciar infraestrutura
- âœ… **EscalÃ¡vel**: Baseado em Cassandra (milhÃµes de operaÃ§Ãµes/seg)
- âœ… **Global**: Deploy multi-regiÃ£o
- âœ… **Free tier**: 25GB grÃ¡tis (suficiente para projetos pequenos)

### 4. Camada de IA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Google Gemini APIs                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                               â”‚
â”‚  1. text-embedding-004                       â”‚
â”‚     Input:  "Texto qualquer..."              â”‚
â”‚     Output: [768 nÃºmeros float]              â”‚
â”‚     Uso:    Converter texto em vetor         â”‚
â”‚                                               â”‚
â”‚  2. gemini-2.5-flash                         â”‚
â”‚     Input:  System + Context + Messages      â”‚
â”‚     Output: Texto gerado                     â”‚
â”‚     Uso:    Gerar respostas do chatbot       â”‚
â”‚                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Modelos escolhidos:**

| Modelo                 | Uso        | Por quÃª?                                                                                        |
| ---------------------- | ---------- | ----------------------------------------------------------------------------------------------- |
| **text-embedding-004** | Embeddings | âœ… 768 dimensÃµes (Ã³timo custo-benefÃ­cio)<br>âœ… MultilÃ­ngue<br>âœ… Velocidade alta<br>âœ… Gratuito |
| **gemini-2.5-flash**   | GeraÃ§Ã£o    | âœ… RÃ¡pido (latÃªncia < 1s)<br>âœ… Custo baixo<br>âœ… Contexto de 1M tokens<br>âœ… Qualidade alta    |

---

## ğŸ“ DecisÃµes Arquiteturais

### Por que Next.js?

âœ… **Server Components** â†’ Menos JavaScript no cliente (mais rÃ¡pido)  
âœ… **API Routes** â†’ Backend integrado (sem servidor separado)  
âœ… **File-based routing** â†’ OrganizaÃ§Ã£o clara  
âœ… **Vercel Deploy** â†’ Deploy com 1 comando

### Por que Vercel AI SDK ao invÃ©s de SDK direto do Gemini?

âœ… **AbstraÃ§Ã£o** â†’ Mesma interface para OpenAI, Anthropic, Gemini  
âœ… **Streaming** â†’ Suporte nativo para respostas em tempo real  
âœ… **React Hooks** â†’ `useChat` simplifica gerenciamento de estado  
âœ… **Type-safe** â†’ TypeScript first-class

### Por que LangChain para scraping?

âœ… **Loaders prontos** â†’ PuppeteerWebBaseLoader jÃ¡ implementado  
âœ… **Text Splitter inteligente** â†’ MantÃ©m contexto entre chunks  
âœ… **Ecossistema** â†’ FÃ¡cil adicionar novos loaders (PDF, YouTube, etc)

**Alternativas consideradas:**

- âŒ Cheerio â†’ NÃ£o funciona com JavaScript-rendered pages
- âŒ Playwright â†’ Similar ao Puppeteer, mas menos adotado
- âš ï¸ Puppeteer puro â†’ Funciona, mas precisa implementar lÃ³gica de chunking

### Por que 512 caracteres de chunk?

**AnÃ¡lise:**

- Muito pequeno (< 200) â†’ Perde contexto, muitas chamadas Ã  API
- Muito grande (> 1000) â†’ Contexto irrelevante, menos precisÃ£o na busca

**Escolha: 512 caracteres**

- âœ… ~1-2 parÃ¡grafos (contexto suficiente)
- âœ… ~100-150 tokens (abaixo do limite ideal para embeddings)
- âœ… SobreposiÃ§Ã£o de 200 chars mantÃ©m continuidade

---

## ğŸ”’ SeguranÃ§a

### VariÃ¡veis de Ambiente

```bash
# âŒ NUNCA faÃ§a isso:
const apiKey = "AIzaSyXXXXXXXXXXXX"

# âœ… Sempre use .env:
GOOGLE_AI_GENERATE=AIzaSyXXXXXXXXXXXX
```

**.gitignore** protege credenciais:

```gitignore
.env
.env.local
.env.production
```

### ValidaÃ§Ã£o de Input

```typescript
// Sempre valide input do usuÃ¡rio
if (!input?.trim()) {
  return; // NÃ£o envia mensagens vazias
}

// Considere adicionar limitaÃ§Ã£o de tamanho
if (input.length > 1000) {
  alert("Mensagem muito longa!");
  return;
}
```

### Rate Limiting

**RecomendaÃ§Ã£o para produÃ§Ã£o:**

```typescript
// Middleware de rate limit (nÃ£o implementado neste projeto)
import { ratelimit } from "@upstash/ratelimit";

const limiter = ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "1 m"), // 10 requests/minuto
});
```

---

## ğŸ“ˆ Performance e OtimizaÃ§Ãµes

### 1. LatÃªncia da API

**Atual:**

```
UsuÃ¡rio envia â†’ Embedding (500ms) â†’ DB Search (200ms) â†’ Generation (1-2s) â†’ Resposta
Total: ~2-3 segundos
```

**OtimizaÃ§Ãµes possÃ­veis:**

- âœ… Cache de embeddings de perguntas comuns (Redis)
- âœ… Streaming de respostas (`streamText` do AI SDK)
- âœ… Prefetch de chunks populares

### 2. Tamanho do Bundle

**Problema:** LangChain Ã© pesado (~2MB)

**SoluÃ§Ã£o:**

```typescript
// âŒ Import completo
import { RecursiveCharacterTextSplitter } from "langchain";

// âœ… Import especÃ­fico (tree-shaking)
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
```

### 3. Server Components

```typescript
// âœ… Renderiza no servidor (0 KB JavaScript)
export default function Page() {
    return <Chat /> // Client Component
}

// âœ… Apenas Chat.tsx vai para o navegador
```

---

## ğŸ§ª Testing (Recomendado para produÃ§Ã£o)

```typescript
// Exemplo de teste unitÃ¡rio (nÃ£o implementado)
describe("Chat API", () => {
  it("should return valid response", async () => {
    const response = await POST({
      json: () => ({ messages: [{ role: "user", content: "test" }] }),
    });

    expect(response.status).toBe(200);
    const data = await response.json();
    expect(data.content).toBeDefined();
  });
});
```

---

## ğŸ“Š Monitoramento (SugestÃµes)

Para produÃ§Ã£o, considere adicionar:

- **Logs estruturados**: Winston, Pino
- **APM**: Sentry, Datadog
- **MÃ©tricas**:
  - LatÃªncia mÃ©dia das respostas
  - Taxa de erro da API
  - Uso de tokens do Gemini
  - Tamanho mÃ©dio do contexto recuperado

---

## ğŸš€ Deploy

### Vercel (Recomendado)

```bash
# Instale CLI da Vercel
npm i -g vercel

# Configure variÃ¡veis de ambiente no dashboard
# https://vercel.com/dashboard â†’ Settings â†’ Environment Variables

# Deploy
vercel --prod
```

### Docker (Alternativa)

```dockerfile
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build
EXPOSE 3000
CMD ["npm", "start"]
```

---

## ğŸ“š ReferÃªncias e Recursos

- [Next.js Documentation](https://nextjs.org/docs)
- [Vercel AI SDK](https://sdk.vercel.ai/docs)
- [Google Gemini API](https://ai.google.dev/docs)
- [Astra DB Docs](https://docs.datastax.com/en/astra/home/astra.html)
- [LangChain Documentation](https://js.langchain.com/docs/)
- [RAG Best Practices](https://www.pinecone.io/learn/retrieval-augmented-generation/)

---

**Ãšltima atualizaÃ§Ã£o**: 2025-12-11
